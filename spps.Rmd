---
title: "SPPS"
output: html_document
editor_options: 
  chunk_output_type: inline
---




```{r, echo=FALSE}
library(tidyverse)
source("scripts/helpers.R")
```
```{r}
# Add a 'year' column to each data frame
SPPS_2017 <- read_csv("data/spps/2017/PoPCites_2017.csv",
                      show_col_types = FALSE) %>%
  mutate(Year = 2017)
SPPS_2018 <- read_csv("data/spps/2018/PoPCites_2018.csv",
                      show_col_types = FALSE) %>%
  mutate(Year = 2018)
SPPS_2019 <- read_csv("data/spps/2019/PoPCites_2019.csv",
                      show_col_types = FALSE)  %>%
  mutate(Year = 2019)
SPPS_2020 <- read_csv("data/spps/2020/PoPCites_2020.csv",
                      show_col_types = FALSE) %>%
  mutate(Year = 2020)
SPPS_2021 <- read_csv("data/spps/2021/PoPCites_2021.csv",
                      show_col_types = FALSE) %>%
  mutate(Year = 2021)
SPPS_2022 <- read_csv("data/spps/2022/PoPCites_2022.csv",
                      show_col_types = FALSE) %>%
  mutate(Year = 2022)


# Combine all the data frames into one
SPPS_combined <- bind_rows(SPPS_2017, SPPS_2018, 
                           SPPS_2019, SPPS_2020, SPPS_2021, SPPS_2022)
  
df<- SPPS_combined

```

```{r}
combined_df <- df %>%
  mutate(
    trimmed_title = 
      str_trunc(
        str_squish(
          str_remove_all(
            str_to_lower(Title),"[[:punct:]]")), 
                side = "right", 
                width = 50, ellipsis = "")) %>%
    mutate(
      # manually matched some titles
      trimmed_title = case_when(
      trimmed_title == "network analysis on attitudes" ~ "network analysis on attitudes a brief tutorial",
      trimmed_title == "equality revisited a cultural metaanalysis of inte" ~ "equality revisited a crosscultural metaanalysis of",
     trimmed_title == "does reducing implicit prejudice increase outgroup
"~  "does reducing prejudice increase outgroup identifi",
      trimmed_title == "forthcominglaypersons beliefs and intuitions about
" ~ "laypersons beliefs and intuitions about free will ",
      trimmed_title == "studying the cognitive map of the us states" ~ "studying the cognitive map of the us states ideolo",
      trimmed_title == "flekova lucie giorgi salvatore hagan courtney kern
" ~ "real men dont say cute using automatic language an",
     trimmed_title == "put the phone down" ~ "put the phone down testing a complementinterfere m" ,
      trimmed_title == "worldview conflict in daily life vol 10 pg 35 2019" ~ "worldview conflict in daily life",
      TRUE ~ trimmed_title
    )) %>%
    mutate(
          Title = str_squish(Title)
  )  %>%
  group_by(trimmed_title) %>%
  arrange(desc(Cites)) %>%  # Sort within each group based on the number of citations
  summarise(
    Title = first(Title),  # Character: Keep first non-NA
    trimmed_title = first(trimmed_title), 
    CombinedCites = sum(Cites, na.rm = TRUE),  # Numeric: Sum
    CombinedAuthors = paste(unique(Authors), collapse = "; "),  # Character: Concatenate unique
    Year = max(Year, na.rm = TRUE),  # Numeric: Max
    Source = first(Source),  # Character: Keep first non-NA
    Publisher = first(Publisher),  # Character: Keep first non-NA
    ArticleURL = first(ArticleURL),  # Character: Keep first non-NA
    CitesURL = first(CitesURL),  # Character: Keep first non-NA
    GSRank = first(GSRank),  # Numeric: Mean
#    QueryDate = first(QueryDate),  # Date: Most recent
#    Type = first(Type),  # Character: Keep first non-NA
    DOI = first(DOI),  # Character: Keep first non-NA
    CitationURL = first(CitationURL),  # Logical: Keep first non-NA
    ECC = first(ECC),  # Numeric: Sum
    CitesPerYear = first(CitesPerYear),  # Numeric: Mean
    CitesPerAuthor = first(CitesPerAuthor),  # Numeric: Mean
    AuthorCount = max(AuthorCount, na.rm = TRUE),  # Numeric: Max
    Age = max(Age, na.rm = TRUE),  # Numeric: max
    Abstract = first(Abstract),  # Character
    FullTextURL = first(FullTextURL),  # Character: Keep first non-NA
    RelatedURL = first(RelatedURL),  # Character: Keep first non-NA
  ) %>% ungroup()  %>% 
  # create unique dummy doi for articles without doi
  mutate(
    DOI_missing = if_else(is.na(DOI), TRUE, FALSE),
    DOI = case_when(
    is.na(DOI) ~ paste0("MISSING_DOI_", trimmed_title),
    TRUE ~ DOI
  ))  %>%
  # must stay separate so that it's easy to replace the dummy doi with the real doi
         mutate(
         DOI = case_when( DOI == "MISSING_DOI_who gets to vote racialized mental images of legit" ~ "10.1177/1948550619899238",
                    TRUE ~ DOI)) %>%
  group_by(DOI) %>%
  arrange(desc(CombinedCites))  %>%  # Sort within each group based on the number of citations
  summarise(
    Title = first(Title),  # Character: Keep first non-NA
    trimmed_title = paste(unique(trimmed_title), collapse = "; "), 
    CombinedCites = sum(CombinedCites, na.rm = TRUE),  # Numeric: Sum
    CombinedAuthors = paste(unique(CombinedAuthors), collapse = "; "),  # Character: Concatenate unique
    Year = max(Year, na.rm = TRUE),  # Numeric: Max
    Source = first(Source),  # Character: Keep first non-NA
    Publisher = first(Publisher),  # Character: Keep first non-NA
    ArticleURL = first(ArticleURL),  # Character: Keep first non-NA
    CitesURL = first(CitesURL),  # Character: Keep first non-NA
    GSRank = first(GSRank),  # Numeric: Mean
#    QueryDate = first(QueryDate),  # Date: Most recent
#    Type = first(Type),  # Character: Keep first non-NA
    DOI = first(DOI),  # Character: Keep first non-NA
    DOI_missing = first(DOI_missing),
    CitationURL = first(CitationURL),  # Logical: Keep first non-NA
    ECC = first(ECC),  # Numeric: Sum
    CitesPerYear = first(CitesPerYear),  # Numeric: Mean
    CitesPerAuthor = first(CitesPerAuthor),  # Numeric: Mean
    AuthorCount = max(AuthorCount, na.rm = TRUE),  # Numeric: Max
    Age = max(Age, na.rm = TRUE),  # Numeric: max
    Abstract = first(Abstract),  # Character
    FullTextURL = first(FullTextURL),  # Character: Keep first non-NA
    RelatedURL = first(RelatedURL),  # Character: Keep first non-NA
  ) %>% ungroup()

```
```{r}
# Remove the grouping


write.csv(SPPS_combined, "data/SPPS_combined.csv")
write.csv(combined_df, "data/SPPS_deduplicated.csv")
df<- combined_df

journal <- "SPPS"

```


There are ``r length(unique(df$DOI))`` articles. The average citation for a paper published in ``r journal`` in our sample was ``r round(mean(df$CombinedCites), digits=3)`` and the median citation was ``r median(df$CombinedCites)``. The minimum citation was ``r min(df$CombinedCites)`` and the maximum citation was ``r max(df$CombinedCites)``. 

```{r}
# make an interactive table
library(DT)

combined_df %>% select(Title, CombinedAuthors, 
                       DOI_missing, DOI, CombinedCites, Year, ArticleURL, FullTextURL, #CitesUrl,
                       CitationURL, RelatedURL) %>%
datatable()
```
